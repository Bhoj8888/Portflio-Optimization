# -*- coding: utf-8 -*-
"""Deploy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TbMc54yN3iDozqAWyeDNVZ3Vg4PtJ9hW
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense, LSTM
import streamlit as st

# Function to fetch data from Yahoo Finance
def fetch_data(tickers, start, end):
    try:
        data = yf.download(tickers, start=start, end=end)
        available_tickers = data.columns.levels[1]
        unavailable_tickers = [ticker for ticker in tickers if ticker not in available_tickers]
        data = data['Adj Close']
        return data, unavailable_tickers
    except Exception as e:
        st.error(f"Error fetching data: {e}")
        return None, tickers

# Function to train and evaluate models
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'LSTM': Sequential([
            LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
            LSTM(50, return_sequences=False),
            Dense(25),
            Dense(y_train.shape[1])
        ])
    }

    rmse_scores = {}

    # Linear Regression and Random Forest
    for name, model in models.items():
        if name != 'LSTM':
            model.fit(X_train.reshape(X_train.shape[0], -1), y_train)
            y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            rmse_scores[name] = rmse

    # LSTM Model
    X_train_lstm = X_train
    X_test_lstm = X_test
    models['LSTM'].compile(optimizer='adam', loss='mean_squared_error')
    models['LSTM'].fit(X_train_lstm, y_train, epochs=5, batch_size=1, verbose=1)
    y_pred_lstm = models['LSTM'].predict(X_test_lstm)
    rmse_scores['LSTM'] = np.sqrt(mean_squared_error(y_test, y_pred_lstm))

    best_model_name = min(rmse_scores, key=rmse_scores.get)
    best_model = models[best_model_name]

    return best_model, best_model_name, rmse_scores

# Function to simulate portfolios and calculate metrics
def simulate_portfolios(mean_returns, cov_matrix, num_portfolios=10000, risk_free_rate=0.01):
    results = np.zeros((3, num_portfolios))
    weights_record = []

    for i in range(num_portfolios):
        weights = np.random.random(len(mean_returns))
        weights /= np.sum(weights)

        portfolio_return = np.sum(weights * mean_returns) * 252
        portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)
        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std_dev

        results[0, i] = portfolio_return
        results[1, i] = portfolio_std_dev
        results[2, i] = sharpe_ratio
        weights_record.append(weights)

    return results, weights_record

# Streamlit app
def main():
    st.title("Stock Portfolio Analysis and Prediction")

    tickers = st.text_input("Enter stock tickers separated by commas", "AAPL, MSFT, GOOGL, AMZN")
    tickers = [ticker.strip() for ticker in tickers.split(',')]

    data, unavailable_tickers = fetch_data(tickers, start="2000-01-01", end="2023-01-01")

    if unavailable_tickers:
        st.error(f"The ticker(s) {', '.join(unavailable_tickers)} you entered is not available for analysis.")
    elif data is None or data.empty:
        st.error("No data fetched for the given tickers.")
    else:
        st.success("Data fetched successfully!")

        # Plot historical stock prices
        st.subheader("Historical Stock Prices")
        st.line_chart(data)

        # Calculate daily returns
        returns = data.pct_change().dropna()

        if returns.empty:
            st.error("No returns data available. Please enter valid tickers.")
            return

        # Summary statistics
        st.subheader("Summary Statistics")
        st.dataframe(returns.describe())

        # Plot return distributions
        st.subheader("Return Distributions")
        st.line_chart(returns)

        # Correlation matrix
        st.subheader("Correlation Matrix")
        st.dataframe(returns.corr())

        # Generate a heatmap of the correlation matrix
        st.subheader("Correlation Matrix Heatmap")
        plt.figure(figsize=(10, 7))
        sns.heatmap(returns.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
        st.pyplot(plt)

        # Portfolio simulation
        num_portfolios = 10000
        mean_returns = returns.mean()
        cov_matrix = returns.cov()
        risk_free_rate = 0.01

        results, weights_record = simulate_portfolios(mean_returns, cov_matrix, num_portfolios, risk_free_rate)

        results_frame = pd.DataFrame(results.T, columns=['Return', 'Standard Deviation', 'Sharpe Ratio'])

        max_sharpe_idx = results_frame['Sharpe Ratio'].idxmax()
        max_sharpe_port = results_frame.iloc[max_sharpe_idx]
        max_sharpe_weights = weights_record[max_sharpe_idx]

        min_vol_idx = results_frame['Standard Deviation'].idxmin()
        min_vol_port = results_frame.iloc[min_vol_idx]
        min_vol_weights = weights_record[min_vol_idx]

        st.subheader("Historical Maximum Sharpe Ratio Portfolio Allocation")
        st.write("Annualized Return:", max_sharpe_port[0])
        st.write("Annualized Standard Deviation:", max_sharpe_port[1])
        st.write("Sharpe Ratio:", max_sharpe_port[2])
        st.write("Weights:", max_sharpe_weights)

        st.subheader("Historical Minimum Volatility Portfolio Allocation")
        st.write("Annualized Return:", min_vol_port[0])
        st.write("Annualized Standard Deviation:", min_vol_port[1])
        st.write("Sharpe Ratio:", min_vol_port[2])
        st.write("Weights:", min_vol_weights)

        # Prepare data for forecasting
        X = returns[:-1].values
        y = returns.shift(-1).dropna().values

        # Reshape X and y for LSTM
        X = X.reshape(X.shape[0], X.shape[1], 1)
        y = y.reshape(y.shape[0], y.shape[1])

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Train and evaluate models
        best_model, best_model_name, rmse_scores = train_and_evaluate_models(X_train, X_test, y_train, y_test)
        st.subheader(f"Best model: {best_model_name}")
        st.write("RMSE Scores:", rmse_scores)

        # Make predictions using the best model
        if best_model_name == 'LSTM':
            predicted_returns = pd.Series(best_model.predict(X_test)[-1], index=tickers)
        else:
            predicted_returns = pd.Series(best_model.predict(X_test.reshape(X_test.shape[0], -1))[-1], index=tickers)

        # Simulate portfolios based on predicted returns
        mean_returns_pred = predicted_returns
        cov_matrix_pred = returns.cov()
        results_pred, weights_record_pred = simulate_portfolios(mean_returns_pred, cov_matrix_pred)

        results_frame_pred = pd.DataFrame(results_pred.T, columns=['Return', 'Standard Deviation', 'Sharpe Ratio'])

        max_sharpe_idx_pred = results_frame_pred['Sharpe Ratio'].idxmax()
        max_sharpe_port_pred = results_frame_pred.iloc[max_sharpe_idx_pred]
        max_sharpe_weights_pred = weights_record_pred[max_sharpe_idx_pred]

        min_vol_idx_pred = results_frame_pred['Standard Deviation'].idxmin()
        min_vol_port_pred = results_frame_pred.iloc[min_vol_idx_pred]
        min_vol_weights_pred = weights_record_pred[min_vol_idx_pred]

        st.subheader("Predicted Maximum Sharpe Ratio Portfolio Allocation")
        st.write("Annualized Return:", max_sharpe_port_pred[0])
        st.write("Annualized Standard Deviation:", max_sharpe_port_pred[1])
        st.write("Sharpe Ratio:", max_sharpe_port_pred[2])
        st.write("Weights:", max_sharpe_weights_pred)

        st.subheader("Predicted Minimum Volatility Portfolio Allocation")
        st.write("Annualized Return:", min_vol_port_pred[0])
        st.write("Annualized Standard Deviation:", min_vol_port_pred[1])
        st.write("Sharpe Ratio:", min_vol_port_pred[2])
        st.write("Weights:", min_vol_weights_pred)

        # Display weights for historical and predicted minimum volatility portfolio
        min_vol_weights_df = pd.DataFrame({
            'Historical': min_vol_weights,
            'Predicted': min_vol_weights_pred
        }, index=tickers)
        st.subheader("Weights for Minimum Volatility Portfolio")
        st.dataframe(min_vol_weights_df)

        # Display weights for historical and predicted maximum Sharpe ratio portfolio
        max_sharpe_weights_df = pd.DataFrame({
            'Historical': max_sharpe_weights,
            'Predicted': max_sharpe_weights_pred
        }, index=tickers)
        st.subheader("Weights for Maximum Sharpe Ratio Portfolio")
        st.dataframe(max_sharpe_weights_df)

        # Plot the historical efficient frontier
        st.subheader("Historical Efficient Frontier")
        plt.figure(figsize=(10, 7))
        plt.scatter(results_frame['Standard Deviation'], results_frame['Return'], c=results_frame['Sharpe Ratio'], cmap='viridis')
        plt.colorbar(label='Sharpe Ratio')
        plt.scatter(max_sharpe_port[1], max_sharpe_port[0], color='r', marker='*', s=200, label='Max Sharpe Ratio')
        plt.scatter(min_vol_port[1], min_vol_port[0], color='b', marker='*', s=200, label='Min Volatility')
        plt.title('Historical Efficient Frontier')
        plt.xlabel('Annualized Standard Deviation')
        plt.ylabel('Annualized Return')
        plt.legend()
        st.pyplot(plt)

        # Plot the predicted efficient frontier
        st.subheader("Predicted Efficient Frontier")
        plt.figure(figsize=(10, 7))
        plt.scatter(results_frame_pred['Standard Deviation'], results_frame_pred['Return'], c=results_frame_pred['Sharpe Ratio'], cmap='viridis')
        plt.colorbar(label='Sharpe Ratio')
        plt.scatter(max_sharpe_port_pred[1], max_sharpe_port_pred[0], color='r', marker='*', s=200, label='Max Sharpe Ratio')
        plt.scatter(min_vol_port_pred[1], min_vol_port_pred[0], color='b', marker='*', s=200, label='Min Volatility')
        plt.title('Predicted Efficient Frontier')
        plt.xlabel('Annualized Standard Deviation')
        plt.ylabel('Annualized Return')
        plt.legend()
        st.pyplot(plt)

        # Plot the weights of the historical and predicted minimum volatility portfolio as pie charts
        st.subheader("Minimum Volatility Portfolio Weights")
        fig, axs = plt.subplots(1, 2, figsize=(14, 7))
        min_vol_weights_df['Historical'].plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axs[0], legend=False)
        axs[0].set_title('Historical Minimum Volatility Portfolio Weights')
        axs[0].set_ylabel('')
        min_vol_weights_df['Predicted'].plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axs[1], legend=False)
        axs[1].set_title('Predicted Minimum Volatility Portfolio Weights')
        axs[1].set_ylabel('')
        st.pyplot(fig)

        # Plot the weights of the historical and predicted maximum Sharpe ratio portfolio as pie charts
        st.subheader("Maximum Sharpe Ratio Portfolio Weights")
        fig, axs = plt.subplots(1, 2, figsize=(14, 7))
        max_sharpe_weights_df['Historical'].plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axs[0], legend=False)
        axs[0].set_title('Historical Maximum Sharpe Ratio Portfolio Weights')
        axs[0].set_ylabel('')
        max_sharpe_weights_df['Predicted'].plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=axs[1], legend=False)
        axs[1].set_title('Predicted Maximum Sharpe Ratio Portfolio Weights')
        axs[1].set_ylabel('')
        st.pyplot(fig)

if __name__ == "__main__":
    main()